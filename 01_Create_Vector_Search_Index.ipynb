{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6538c3ea-508d-492f-bdcc-e4fccfc95d5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.3.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (0.3.2)\nRequirement already satisfied: langchain-experimental==0.3.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (0.3.2)\nRequirement already satisfied: langgraph==0.2.34 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (0.2.34)\nRequirement already satisfied: langchain-databricks==0.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (0.1.0)\nCollecting datasets==3.0.2\n  Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 472.7/472.7 kB 6.8 MB/s eta 0:00:00\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain==0.3.2) (0.3.0)\nRequirement already satisfied: numpy<2,>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain==0.3.2) (1.26.4)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain==0.3.2) (0.1.137)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain==0.3.2) (4.0.3)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain==0.3.2) (3.10.10)\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.3.2) (2.28.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain==0.3.2) (2.9.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain==0.3.2) (2.0.36)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain==0.3.2) (0.3.13)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.3.2) (8.1.0)\nRequirement already satisfied: PyYAML>=5.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain==0.3.2) (6.0.2)\nRequirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain-experimental==0.3.2) (0.3.1)\nRequirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langgraph==0.2.34) (2.0.2)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.10/site-packages (from langchain-databricks==0.1.0) (1.10.0)\nRequirement already satisfied: mlflow>=2.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain-databricks==0.1.0) (2.17.1)\nRequirement already satisfied: databricks-vectorsearch<0.41,>=0.40 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain-databricks==0.1.0) (0.40)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.10/site-packages (from datasets==3.0.2) (1.5.3)\nCollecting fsspec[http]<=2024.9.0,>=2023.1.0\n  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 179.3/179.3 kB 8.6 MB/s eta 0:00:00\nCollecting tqdm>=4.66.3\n  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.4/78.4 kB 10.4 MB/s eta 0:00:00\nCollecting xxhash\n  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.1/194.1 kB 13.0 MB/s eta 0:00:00\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.10/site-packages (from datasets==3.0.2) (23.2)\nCollecting dill<0.3.9,>=0.3.0\n  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.3/116.3 kB 9.1 MB/s eta 0:00:00\nCollecting requests<3,>=2\n  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.9/64.9 kB 9.5 MB/s eta 0:00:00\nCollecting pyarrow>=15.0.0\n  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.9/39.9 MB 46.3 MB/s eta 0:00:00\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.2) (3.16.1)\nCollecting multiprocess<0.70.17\n  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.8/134.8 kB 31.7 MB/s eta 0:00:00\nCollecting huggingface-hub>=0.23.0\n  Downloading huggingface_hub-0.26.1-py3-none-any.whl (447 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 447.4/447.4 kB 41.4 MB/s eta 0:00:00\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.2) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.2) (6.1.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.2) (2.4.3)\nRequirement already satisfied: yarl<2.0,>=1.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.2) (1.16.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.2) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.2) (22.1.0)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.10/site-packages (from databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (4.25.5)\nRequirement already satisfied: mlflow-skinny<3,>=2.11.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (2.17.1)\nRequirement already satisfied: deprecation>=2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (2.1.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets==3.0.2) (4.12.2)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (2.6.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (0.6.7)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.8->langchain==0.3.2) (1.33)\nRequirement already satisfied: msgpack<2.0.0,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph==0.2.34) (1.1.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.2) (1.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.2) (3.10.10)\nRequirement already satisfied: httpx<1,>=0.23.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.2) (0.27.2)\nRequirement already satisfied: docker<8,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from mlflow>=2.9->langchain-databricks==0.1.0) (7.1.0)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow>=2.9->langchain-databricks==0.1.0) (3.7.0)\nRequirement already satisfied: Flask<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from mlflow>=2.9->langchain-databricks==0.1.0) (3.0.3)\nRequirement already satisfied: graphene<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from mlflow>=2.9->langchain-databricks==0.1.0) (3.4.1)\nRequirement already satisfied: markdown<4,>=3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from mlflow>=2.9->langchain-databricks==0.1.0) (3.7)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow>=2.9->langchain-databricks==0.1.0) (1.1.1)\nRequirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.10/site-packages (from mlflow>=2.9->langchain-databricks==0.1.0) (3.1.2)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from mlflow>=2.9->langchain-databricks==0.1.0) (1.13.3)\nRequirement already satisfied: gunicorn<24 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from mlflow>=2.9->langchain-databricks==0.1.0) (23.0.0)\nRequirement already satisfied: click<9,>=7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (8.1.7)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (0.20.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (1.27.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (1.27.0)\nRequirement already satisfied: cloudpickle<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (3.1.0)\nRequirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (8.4.0)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (5.3.2)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (3.1.43)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (0.5.1)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->datasets==3.0.2) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->datasets==3.0.2) (2022.7)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.2) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.2) (2.23.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.2) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.2) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.2) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.2) (2.0.4)\nRequirement already satisfied: greenlet!=0.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.2) (3.1.1)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow>=2.9->langchain-databricks==0.1.0) (1.3.6)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (3.23.0)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (0.9.0)\nRequirement already satisfied: Werkzeug>=3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from Flask<4->mlflow>=2.9->langchain-databricks==0.1.0) (3.0.6)\nRequirement already satisfied: blinker>=1.6.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from Flask<4->mlflow>=2.9->langchain-databricks==0.1.0) (1.8.2)\nRequirement already satisfied: itsdangerous>=2.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from Flask<4->mlflow>=2.9->langchain-databricks==0.1.0) (2.2.0)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from graphene<4->mlflow>=2.9->langchain-databricks==0.1.0) (3.2.5)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from graphene<4->mlflow>=2.9->langchain-databricks==0.1.0) (3.2.0)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.2) (1.2.0)\nRequirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.2) (1.0.6)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.2) (3.5.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.2) (0.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow>=2.9->langchain-databricks==0.1.0) (2.1.1)\nRequirement already satisfied: jsonpointer>=1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.8->langchain==0.3.2) (3.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.9->langchain-databricks==0.1.0) (3.0.9)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.9->langchain-databricks==0.1.0) (0.11.0)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.9->langchain-databricks==0.1.0) (9.4.0)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.9->langchain-databricks==0.1.0) (1.0.5)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.9->langchain-databricks==0.1.0) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.9->langchain-databricks==0.1.0) (1.4.4)\nRequirement already satisfied: python-dotenv>=0.21.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (1.0.1)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==3.0.2) (1.16.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow>=2.9->langchain-databricks==0.1.0) (2.2.0)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow>=2.9->langchain-databricks==0.1.0) (1.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain==0.3.2) (0.2.0)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (2.28.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (4.0.11)\nRequirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (1.0.0)\nRequirement already satisfied: deprecated>=1.2.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (1.2.14)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (0.48b0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (0.4.3)\nRequirement already satisfied: wrapt<2,>=1.10 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (1.16.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (5.0.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (4.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (0.3.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /databricks/python3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<3,>=2.11.3->databricks-vectorsearch<0.41,>=0.40->langchain-databricks==0.1.0) (0.5.1)\nInstalling collected packages: xxhash, tqdm, requests, pyarrow, fsspec, dill, multiprocess, huggingface-hub, datasets\n  Attempting uninstall: requests\n    Found existing installation: requests 2.28.1\n    Not uninstalling requests at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378\n    Can't uninstall 'requests'. No files were found to uninstall.\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 8.0.0\n    Not uninstalling pyarrow at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378\n    Can't uninstall 'pyarrow'. No files were found to uninstall.\nSuccessfully installed datasets-3.0.2 dill-0.3.8 fsspec-2024.9.0 huggingface-hub-0.26.1 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 tqdm-4.66.5 xxhash-3.5.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain==0.3.2 langchain-experimental==0.3.2 langgraph==0.2.34 langchain-databricks==0.1.0 datasets==3.0.2\n",
    "\n",
    "dbutils.library.restartPython()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b954d58d-8b16-4c74-97ba-a708acfd6373",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8eade09-225a-49aa-8826-c8cf17c917ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "catalog_name = CATALOG_NAME\n",
    "schema_name = SCHEMA_NAME\n",
    "\n",
    "# Source Table\n",
    "table_name = TABLE_NAME\n",
    "source_table_fullname = f\"{catalog_name}.{schema_name}.{table_name}\"\n",
    "\n",
    "#  Vector Search Endpoint\n",
    "vs_endpoint_name = VS_ENDPOINT_NAME\n",
    "\n",
    "# Vector Search index\n",
    "vs_index = VS_INDEX\n",
    "vs_index_table_fullname = f\"{catalog_name}.{schema_name}.{vs_index}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf2a433d-cd33-4b21-aa20-aebe2306e139",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cae862e-5958-4c78-bf1c-b795fbdaa80b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE VOLUME IF NOT EXISTS cache;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22c315b6-e65e-4e1e-b604-355445618622",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:45: UserWarning: The cache_dir for this dataset is workspace_us.default.cache, which is not a persistent path.Therefore, if/when the cluster restarts, the downloaded dataset will be lost.The persistent storage options for this workspace/cluster config are: [UC Volumes].Please update either `cache_dir` or the environment variable `HF_DATASETS_CACHE`to be under one of the following root directories: ['/Volumes/']\n  warnings.warn(warning_message)\n/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:14: UserWarning: During large dataset downloads, there could be multiple progress bar widgets that can cause performance issues for your notebook or browser. To avoid these issues, use `datasets.utils.logging.disable_progress_bar()` to turn off the progress bars.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beafa7eec15f4483b1fa3a974c47c093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ext Classification Dataset Processed.csv:   0%|          | 0.00/120M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98e5aeac4184d05acaa00b3a51f8280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "# os.environ['HF_DATASETS_CACHE'] = \"/Volumes/\"\n",
    "# Define a persistent cache directory\n",
    "cache_dir = \"workspace_us.default.cache\"\n",
    "split = \"train[:20%]\" # 10K samples\n",
    "\n",
    "# Load dataset from Hugging Face, limit to 50%\n",
    "dataset = load_dataset(\"owaiskha9654/PubMed_MultiLabel_Text_Classification_Dataset_MeSH\", split=split, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa60d489-98c0-4d61-802e-a0b1a6b2ae22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n['Title', 'abstractText', 'meshMajor', 'pmid', 'meshid', 'meshroot', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'Z']\n10000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.column_names))\n",
    "print(dataset.column_names)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7aec1af-e0dd-420e-bfd4-b9afea67243e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Create Source Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62141d75-5be3-4602-a4ed-6f35975a17ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/pyspark/sql/connect/expressions.py:956: UserWarning: WARN WindowExpression: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, concat, lit\n",
    "\n",
    "# The dataset has Title, abstractText, and meshMajor columns\n",
    "pmid = dataset[\"pmid\"]\n",
    "title = dataset['Title']\n",
    "abstract_text = dataset['abstractText']\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(zip(pmid, title, abstract_text), [\"pmid\", \"title\", \"abstract_text\"])\n",
    "df = df.withColumn(\"pmid\", df[\"pmid\"].cast(\"string\"))\n",
    "\n",
    "# Create content column\n",
    "df = df.withColumn(\"content\", concat(lit(\"Title: \"), df[\"title\"], lit(\"\\nAbstract: \"), df[\"abstract_text\"]))\n",
    "\n",
    "# Drop columns title, abstract\n",
    "df = df.drop('title', 'abstract_text')\n",
    "\n",
    "# Drop  null\n",
    "df = df.dropna()\n",
    "\n",
    "# Add a contiguous 'id' column starting from 1\n",
    "window_spec = Window.orderBy(\"content\")\n",
    "df = df.withColumn(\"id\", row_number().over(window_spec))\n",
    "\n",
    "# Save DataFrame as a Delta table\n",
    "df.write.format(\"delta\").option(\"overwriteSchema\", \"true\").option(\"delta.enableChangeDataFeed\", \"true\").mode(\"overwrite\").saveAsTable(source_table_fullname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3594a6d8-e21e-4d9e-88f1-fd8c9db40587",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Create Vector Search Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0243d4b1-8384-4d2d-9c94-95848ed9d402",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\nEndpoint named pubned_vs_endpoint is ready.\nWaiting for endpoint to be ready, this can take a few min... {'name': 'pubned_vs_endpoint', 'creator': 'nt@neoedu.co.th', 'creation_timestamp': 1730105043063, 'last_updated_timestamp': 1730105043063, 'endpoint_type': 'STANDARD', 'last_updated_user': 'nt@neoedu.co.th', 'id': '22d4102f-6fe9-4328-8971-497579875cd7', 'endpoint_status': {'state': 'PROVISIONING'}, 'num_indexes': 0}\nWaiting for endpoint to be ready, this can take a few min... {'name': 'pubned_vs_endpoint', 'creator': 'nt@neoedu.co.th', 'creation_timestamp': 1730105043063, 'last_updated_timestamp': 1730105043063, 'endpoint_type': 'STANDARD', 'last_updated_user': 'nt@neoedu.co.th', 'id': '22d4102f-6fe9-4328-8971-497579875cd7', 'endpoint_status': {'state': 'PROVISIONING'}, 'num_indexes': 0}\nWaiting for endpoint to be ready, this can take a few min... {'name': 'pubned_vs_endpoint', 'creator': 'nt@neoedu.co.th', 'creation_timestamp': 1730105043063, 'last_updated_timestamp': 1730105043063, 'endpoint_type': 'STANDARD', 'last_updated_user': 'nt@neoedu.co.th', 'id': '22d4102f-6fe9-4328-8971-497579875cd7', 'endpoint_status': {'state': 'PROVISIONING'}, 'num_indexes': 0}\nWaiting for endpoint to be ready, this can take a few min... {'name': 'pubned_vs_endpoint', 'creator': 'nt@neoedu.co.th', 'creation_timestamp': 1730105043063, 'last_updated_timestamp': 1730105043063, 'endpoint_type': 'STANDARD', 'last_updated_user': 'nt@neoedu.co.th', 'id': '22d4102f-6fe9-4328-8971-497579875cd7', 'endpoint_status': {'state': 'PROVISIONING'}, 'num_indexes': 0}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'name': 'pubned_vs_endpoint',\n",
       " 'creator': 'nt@neoedu.co.th',\n",
       " 'creation_timestamp': 1730105043063,\n",
       " 'last_updated_timestamp': 1730105043063,\n",
       " 'endpoint_type': 'STANDARD',\n",
       " 'last_updated_user': 'nt@neoedu.co.th',\n",
       " 'id': '22d4102f-6fe9-4328-8971-497579875cd7',\n",
       " 'endpoint_status': {'state': 'ONLINE'},\n",
       " 'num_indexes': 0}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Create VEctor Search Endpoint\n",
    "\n",
    "import time\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "def wait_for_vs_endpoint_to_be_ready(vsc, vs_endpoint_name):\n",
    "  for i in range(180):\n",
    "    endpoint = vsc.get_endpoint(vs_endpoint_name)\n",
    "    status = endpoint.get(\"endpoint_status\", endpoint.get(\"status\"))[\"state\"].upper()\n",
    "    if \"ONLINE\" in status:\n",
    "      return endpoint\n",
    "    elif \"PROVISIONING\" in status or i <6:\n",
    "      if i % 20 == 0: \n",
    "        print(f\"Waiting for endpoint to be ready, this can take a few min... {endpoint}\")\n",
    "      time.sleep(10)\n",
    "    else:\n",
    "      raise Exception(f'''Error with the endpoint {vs_endpoint_name}. - this shouldn't happen: {endpoint}.\\n Please delete it and re-run the previous cell: vsc.delete_endpoint(\"{vs_endpoint_name}\")''')\n",
    "  raise Exception(f\"Timeout, your endpoint isn't ready yet: {vsc.get_endpoint(vs_endpoint_name)}\")\n",
    "\n",
    "def create_vs_endpoint(vs_endpoint_name):\n",
    "\n",
    "    # check if the endpoint exists\n",
    "    if vs_endpoint_name not in [e['name'] for e in vsc.list_endpoints()['endpoints']]:\n",
    "        vsc.create_endpoint(name=vs_endpoint_name, endpoint_type=\"STANDARD\")\n",
    "\n",
    "    # check the status of the endpoint\n",
    "    wait_for_vs_endpoint_to_be_ready(vsc, vs_endpoint_name)\n",
    "    print(f\"Endpoint named {vs_endpoint_name} is ready.\")\n",
    "\n",
    "vsc = VectorSearchClient()\n",
    "\n",
    "#  Create a new endpoint if not exist\n",
    "vsc.create_endpoint(name=vs_endpoint_name, endpoint_type=\"STANDARD\")\n",
    "print(f\"Endpoint named {vs_endpoint_name} is ready.\")\n",
    "\n",
    "wait_for_vs_endpoint_to_be_ready(vsc, vs_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "726e98ee-5e8b-4b33-8e86-c12452010686",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Create Vector Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fec767f-6e51-4fb2-8dfd-4d7ff3ea6098",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error processing request 404 Client Error: Not Found for url: https://oregon.cloud.databricks.com/api/2.0/vector-search/endpoints/pubned_vs_endpoint/indexes/workspace_us.default.pubmed_index\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index workspace_us.default.pubmed_index on endpoint pubned_vs_endpoint...\n"
     ]
    }
   ],
   "source": [
    "# Create or sync the index\n",
    "\n",
    "def index_exists(vsc, endpoint_name, index_full_name):\n",
    "  try:\n",
    "      dict_vsindex = vsc.get_index(endpoint_name, index_full_name).describe()\n",
    "      return dict_vsindex.get('status').get('ready', False)\n",
    "  except Exception as e:\n",
    "      if 'RESOURCE_DOES_NOT_EXIST' not in str(e):\n",
    "          print(f'Unexpected error describing the index. This could be a permission issue.')\n",
    "          raise e\n",
    "  return False\n",
    "\n",
    "embedding_model_endpoint = \"databricks-bge-large-en\"\n",
    "\n",
    "if not index_exists(vsc, vs_endpoint_name, vs_index_table_fullname):\n",
    "    print(f\"Creating index {vs_index_table_fullname} on endpoint {vs_endpoint_name}...\")\n",
    "        \n",
    "    vsc.create_delta_sync_index(\n",
    "        endpoint_name=vs_endpoint_name,\n",
    "        index_name=vs_index_table_fullname,\n",
    "        source_table_name= source_table_fullname,\n",
    "        pipeline_type=\"TRIGGERED\", #Sync needs to be manually triggered\n",
    "        primary_key=\"id\",\n",
    "        embedding_source_column=\"content\",\n",
    "        embedding_model_endpoint_name=embedding_model_endpoint\n",
    "        )\n",
    "else:\n",
    "    # Trigger a sync to update our vs content with the new data saved in the table\n",
    "    vsc.get_index(vs_endpoint_name, vs_index_table_fullname).sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7480671-7b2a-4dc2-8678-6605e39f7459",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for index to be ready, this can take a few min... {'detailed_state': 'PROVISIONING_PIPELINE_RESOURCES', 'message': 'Index is currently pending setup of pipeline resources. Check latest status: https://dbc-d1407b2d-ba16.cloud.databricks.com/explore/data/workspace_us/default/pubmed_index', 'indexed_row_count': 0, 'provisioning_status': {'provisioning_pipeline_time_spent_seconds': 36.0}, 'ready': False, 'index_url': 'dbc-d1407b2d-ba16.cloud.databricks.com/api/2.0/vector-search/endpoints/pubned_vs_endpoint/indexes/workspace_us.default.pubmed_index'} - pipeline url:dbc-d1407b2d-ba16.cloud.databricks.com/api/2.0/vector-search/endpoints/pubned_vs_endpoint/indexes/workspace_us.default.pubmed_index\nWaiting for index to be ready, this can take a few min... {'detailed_state': 'PROVISIONING_INITIAL_SNAPSHOT', 'message': 'Index is currently is in the process of syncing initial data. Check latest status: https://dbc-d1407b2d-ba16.cloud.databricks.com/explore/data/workspace_us/default/pubmed_index', 'indexed_row_count': 580, 'provisioning_status': {'initial_pipeline_sync_progress': {'latest_version_currently_processing': 1, 'num_synced_rows': 600, 'total_rows_to_sync': 9999, 'sync_progress_completion': 0.06, 'estimated_completion_time_seconds': 3764.4023, 'pipeline_metrics': {'total_sync_time_per_row_ms': 400.4683, 'ingestion_metrics': {'ingestion_time_per_row_ms': 7.8917, 'ingestion_batch_size': 20}, 'embedding_metrics': {'embedding_generation_time_per_row_ms': 384.4533, 'embedding_generation_batch_size': 150}}}}, 'ready': False, 'index_url': 'dbc-d1407b2d-ba16.cloud.databricks.com/api/2.0/vector-search/endpoints/pubned_vs_endpoint/indexes/workspace_us.default.pubmed_index'} - pipeline url:dbc-d1407b2d-ba16.cloud.databricks.com/api/2.0/vector-search/endpoints/pubned_vs_endpoint/indexes/workspace_us.default.pubmed_index\nWaiting for index to be ready, this can take a few min... {'detailed_state': 'PROVISIONING_INITIAL_SNAPSHOT', 'message': 'Index is currently is in the process of syncing initial data. Check latest status: https://dbc-d1407b2d-ba16.cloud.databricks.com/explore/data/workspace_us/default/pubmed_index', 'indexed_row_count': 1460, 'provisioning_status': {'initial_pipeline_sync_progress': {'latest_version_currently_processing': 1, 'num_synced_rows': 1520, 'total_rows_to_sync': 9999, 'sync_progress_completion': 0.152, 'estimated_completion_time_seconds': 3717.1411, 'pipeline_metrics': {'total_sync_time_per_row_ms': 438.3421, 'ingestion_metrics': {'ingestion_time_per_row_ms': 7.3803, 'ingestion_batch_size': 20}, 'embedding_metrics': {'embedding_generation_time_per_row_ms': 425.3026, 'embedding_generation_batch_size': 150}}}}, 'ready': False, 'index_url': 'dbc-d1407b2d-ba16.cloud.databricks.com/api/2.0/vector-search/endpoints/pubned_vs_endpoint/indexes/workspace_us.default.pubmed_index'} - pipeline url:dbc-d1407b2d-ba16.cloud.databricks.com/api/2.0/vector-search/endpoints/pubned_vs_endpoint/indexes/workspace_us.default.pubmed_index\nWaiting for index to be ready, this can take a few min... {'detailed_state': 'PROVISIONING_INITIAL_SNAPSHOT', 'message': 'Index is currently is in the process of syncing initial data. Check latest status: https://dbc-d1407b2d-ba16.cloud.databricks.com/explore/data/workspace_us/default/pubmed_index', 'indexed_row_count': 2420, 'provisioning_status': {'initial_pipeline_sync_progress': {'latest_version_currently_processing': 1, 'num_synced_rows': 2420, 'total_rows_to_sync': 9999, 'sync_progress_completion': 0.242, 'estimated_completion_time_seconds': 3418.5957, 'pipeline_metrics': {'total_sync_time_per_row_ms': 451.0021, 'ingestion_metrics': {'ingestion_time_per_row_ms': 7.3876, 'ingestion_batch_size': 20}, 'embedding_metrics': {'embedding_generation_time_per_row_ms': 438.6905, 'embedding_generation_batch_size': 150}}}}, 'ready': False, 'index_url': 'dbc-d1407b2d-ba16.cloud.databricks.com/api/2.0/vector-search/endpoints/pubned_vs_endpoint/indexes/workspace_us.default.pubmed_index'} - pipeline url:dbc-d1407b2d-ba16.cloud.databricks.com/api/2.0/vector-search/endpoints/pubned_vs_endpoint/indexes/workspace_us.default.pubmed_index\nWaiting for index to be ready, this can take a few min... {'detailed_state': 'PROVISIONING_INITIAL_SNAPSHOT', 'message': 'Index is currently is in the process of syncing initial data. Check latest status: https://dbc-d1407b2d-ba16.cloud.databricks.com/explore/data/workspace_us/default/pubmed_index', 'indexed_row_count': 3220, 'provisioning_status': {'initial_pipeline_sync_progress': {'latest_version_currently_processing': 1, 'num_synced_rows': 3260, 'total_rows_to_sync': 9999, 'sync_progress_completion': 0.326, 'estimated_completion_time_seconds': 3130.8086, 'pipeline_metrics': {'total_sync_time_per_row_ms': 464.5117, 'ingestion_metrics': {'ingestion_time_per_row_ms': 7.0951, 'ingestion_batch_size': 20}, 'embedding_metrics': {'embedding_generation_time_per_row_ms': 452.8138, 'embedding_generation_batch_size': 150}}}}, 'ready': False, 'index_url': 'dbc-d1407b2d-ba16.cloud.databricks.com/api/2.0/vector-search/endpoints/pubned_vs_endpoint/indexes/workspace_us.default.pubmed_index'} - pipeline url:dbc-d1407b2d-ba16.cloud.databricks.com/api/2.0/vector-search/endpoints/pubned_vs_endpoint/indexes/workspace_us.default.pubmed_index\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error processing request 400 Client Error: Bad Request for url: https://oregon.cloud.databricks.com/api/2.0/vector-search/endpoints/workspace_us.default.pubmed_index/indexes/pubned_vs_endpoint\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages/databricks/vector_search/utils.py:78\u001B[0m, in \u001B[0;36mRequestUtils.issue_request\u001B[0;34m(url, method, token, params, json, verify, auth, data, headers)\u001B[0m\n",
       "\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 78\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages/requests/models.py:1024\u001B[0m, in \u001B[0;36mResponse.raise_for_status\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m   1023\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_error_msg:\n",
       "\u001B[0;32m-> 1024\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(http_error_msg, response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
       "\n",
       "\u001B[0;31mHTTPError\u001B[0m: 400 Client Error: Bad Request for url: https://oregon.cloud.databricks.com/api/2.0/vector-search/endpoints/workspace_us.default.pubmed_index/indexes/pubned_vs_endpoint\n",
       "\n",
       "During handling of the above exception, another exception occurred:\n",
       "\n",
       "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1677135527139183>, line 20\u001B[0m\n",
       "\u001B[1;32m     17\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTimeout, your index isn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt ready yet: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvsc\u001B[38;5;241m.\u001B[39mget_index(index_name, vs_endpoint_name)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Let's wait for the index to be ready and all our embeddings to be created and indexed\u001B[39;00m\n",
       "\u001B[0;32m---> 20\u001B[0m wait_for_index_to_be_ready(vsc, vs_endpoint_name, vs_index_table_fullname)\n",
       "\n",
       "File \u001B[0;32m<command-1677135527139183>, line 17\u001B[0m, in \u001B[0;36mwait_for_index_to_be_ready\u001B[0;34m(vsc, vs_endpoint_name, index_name)\u001B[0m\n",
       "\u001B[1;32m     15\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m     16\u001B[0m       \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'''\u001B[39m\u001B[38;5;124mError with the index - this shouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt happen. DLT pipeline might have been killed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m Please delete it and re-run the previous cell: vsc.delete_index(\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mindex_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvs_endpoint_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m) \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mIndex details: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00midx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'''\u001B[39m)\n",
       "\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTimeout, your index isn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt ready yet: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvsc\u001B[38;5;241m.\u001B[39mget_index(index_name, vs_endpoint_name)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages/databricks/vector_search/client.py:433\u001B[0m, in \u001B[0;36mVectorSearchClient.get_index\u001B[0;34m(self, endpoint_name, index_name)\u001B[0m\n",
       "\u001B[1;32m    426\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    427\u001B[0m \u001B[38;5;124;03mGet an index.\u001B[39;00m\n",
       "\u001B[1;32m    428\u001B[0m \n",
       "\u001B[1;32m    429\u001B[0m \u001B[38;5;124;03m:param Option[str] endpoint_name: The optional name of the endpoint.\u001B[39;00m\n",
       "\u001B[1;32m    430\u001B[0m \u001B[38;5;124;03m:param str index_name: The name of the index.\u001B[39;00m\n",
       "\u001B[1;32m    431\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    432\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m index_name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIndex name must be specified\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m--> 433\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[43mRequestUtils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43missue_request\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    434\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_index_url\u001B[49m\u001B[43m(\u001B[49m\u001B[43mendpoint_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    435\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_token_for_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    436\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    437\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    438\u001B[0m index_url \u001B[38;5;241m=\u001B[39m resp\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m'\u001B[39m, {})\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindex_url\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[1;32m    439\u001B[0m response_endpoint_name \u001B[38;5;241m=\u001B[39m resp\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mendpoint_name\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages/databricks/vector_search/utils.py:81\u001B[0m, in \u001B[0;36mRequestUtils.issue_request\u001B[0;34m(url, method, token, params, json, verify, auth, data, headers)\u001B[0m\n",
       "\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m     80\u001B[0m     logging\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError processing request \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[0;32m---> 81\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n",
       "\u001B[1;32m     82\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mResponse content \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mcontent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, status_code \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m     83\u001B[0m     )\n",
       "\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\u001B[38;5;241m.\u001B[39mjson()\n",
       "\n",
       "\u001B[0;31mException\u001B[0m: Response content b'{\"error_code\":\"INVALID_PARAMETER_VALUE\",\"message\":\"Invalid index name. Must specify the full index name <catalog>.<schema>.<table>. Only alphanumerics and underscores are allowed.\"}', status_code 400"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "Exception",
        "evalue": "Response content b'{\"error_code\":\"INVALID_PARAMETER_VALUE\",\"message\":\"Invalid index name. Must specify the full index name <catalog>.<schema>.<table>. Only alphanumerics and underscores are allowed.\"}', status_code 400"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>Exception</span>: Response content b'{\"error_code\":\"INVALID_PARAMETER_VALUE\",\"message\":\"Invalid index name. Must specify the full index name <catalog>.<schema>.<table>. Only alphanumerics and underscores are allowed.\"}', status_code 400"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages/databricks/vector_search/utils.py:78\u001B[0m, in \u001B[0;36mRequestUtils.issue_request\u001B[0;34m(url, method, token, params, json, verify, auth, data, headers)\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 78\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages/requests/models.py:1024\u001B[0m, in \u001B[0;36mResponse.raise_for_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1023\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_error_msg:\n\u001B[0;32m-> 1024\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(http_error_msg, response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
        "\u001B[0;31mHTTPError\u001B[0m: 400 Client Error: Bad Request for url: https://oregon.cloud.databricks.com/api/2.0/vector-search/endpoints/workspace_us.default.pubmed_index/indexes/pubned_vs_endpoint",
        "\nDuring handling of the above exception, another exception occurred:\n",
        "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-1677135527139183>, line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTimeout, your index isn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt ready yet: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvsc\u001B[38;5;241m.\u001B[39mget_index(index_name, vs_endpoint_name)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Let's wait for the index to be ready and all our embeddings to be created and indexed\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m wait_for_index_to_be_ready(vsc, vs_endpoint_name, vs_index_table_fullname)\n",
        "File \u001B[0;32m<command-1677135527139183>, line 17\u001B[0m, in \u001B[0;36mwait_for_index_to_be_ready\u001B[0;34m(vsc, vs_endpoint_name, index_name)\u001B[0m\n\u001B[1;32m     15\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     16\u001B[0m       \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'''\u001B[39m\u001B[38;5;124mError with the index - this shouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt happen. DLT pipeline might have been killed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m Please delete it and re-run the previous cell: vsc.delete_index(\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mindex_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvs_endpoint_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m) \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mIndex details: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00midx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'''\u001B[39m)\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTimeout, your index isn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt ready yet: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvsc\u001B[38;5;241m.\u001B[39mget_index(index_name, vs_endpoint_name)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages/databricks/vector_search/client.py:433\u001B[0m, in \u001B[0;36mVectorSearchClient.get_index\u001B[0;34m(self, endpoint_name, index_name)\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;124;03mGet an index.\u001B[39;00m\n\u001B[1;32m    428\u001B[0m \n\u001B[1;32m    429\u001B[0m \u001B[38;5;124;03m:param Option[str] endpoint_name: The optional name of the endpoint.\u001B[39;00m\n\u001B[1;32m    430\u001B[0m \u001B[38;5;124;03m:param str index_name: The name of the index.\u001B[39;00m\n\u001B[1;32m    431\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m index_name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIndex name must be specified\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 433\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[43mRequestUtils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43missue_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    434\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_index_url\u001B[49m\u001B[43m(\u001B[49m\u001B[43mendpoint_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    435\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_token_for_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    436\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    437\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    438\u001B[0m index_url \u001B[38;5;241m=\u001B[39m resp\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m'\u001B[39m, {})\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindex_url\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    439\u001B[0m response_endpoint_name \u001B[38;5;241m=\u001B[39m resp\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mendpoint_name\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-66e6a84c-bb99-44c9-8991-f90551b96378/lib/python3.10/site-packages/databricks/vector_search/utils.py:81\u001B[0m, in \u001B[0;36mRequestUtils.issue_request\u001B[0;34m(url, method, token, params, json, verify, auth, data, headers)\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     80\u001B[0m     logging\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError processing request \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 81\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n\u001B[1;32m     82\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mResponse content \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mcontent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, status_code \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     83\u001B[0m     )\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\u001B[38;5;241m.\u001B[39mjson()\n",
        "\u001B[0;31mException\u001B[0m: Response content b'{\"error_code\":\"INVALID_PARAMETER_VALUE\",\"message\":\"Invalid index name. Must specify the full index name <catalog>.<schema>.<table>. Only alphanumerics and underscores are allowed.\"}', status_code 400"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def wait_for_index_to_be_ready(vsc, vs_endpoint_name, index_name):\n",
    "  for i in range(180):\n",
    "    idx = vsc.get_index(vs_endpoint_name, index_name).describe()\n",
    "    index_status = idx.get('status', idx.get('index_status', {}))\n",
    "    status = index_status.get('detailed_state', index_status.get('status', 'UNKNOWN')).upper()\n",
    "    url = index_status.get('index_url', index_status.get('url', 'UNKNOWN'))\n",
    "    if \"ONLINE\" in status:\n",
    "      return\n",
    "    if \"UNKNOWN\" in status:\n",
    "      print(f\"Can't get the status - will assume index is ready {idx} - url: {url}\")\n",
    "      return\n",
    "    elif \"PROVISIONING\" in status:\n",
    "      if i % 40 == 0: print(f\"Waiting for index to be ready, this can take a few min... {index_status} - pipeline url:{url}\")\n",
    "      time.sleep(10)\n",
    "    else:\n",
    "        raise Exception(f'''Error with the index - this shouldn't happen. DLT pipeline might have been killed.\\n Please delete it and re-run the previous cell: vsc.delete_index(\"{index_name}, {vs_endpoint_name}\") \\nIndex details: {idx}''')\n",
    "  raise Exception(f\"Timeout, your index isn't ready yet: {vsc.get_index(index_name, vs_endpoint_name)}\")\n",
    "\n",
    "# Let's wait for the index to be ready and all our embeddings to be created and indexed\n",
    "wait_for_index_to_be_ready(vsc, vs_endpoint_name, vs_index_table_fullname)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1677135527139202,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Create_Vector_Search_Index",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
